# 十、MySQL刷页

​	前面介绍过，InnoDB在处理更新语句的时候，只做了写日志这一个磁盘操作。这个日志叫作redo log（重做日志），在更新内存写完redo log后，就返回给客户端，本次更新成功。数据库把内存里的数据写入磁盘的过程，称为"flush"。

> 将脏页flush到磁盘上是直接将脏页数据覆盖到对应磁盘上的数据。
>
> Redolog 的空间是循环使用的，无所谓释放。 对应的内存页会变成干净页，但是等淘汰的时候才会逐出内存

​	**当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”**。不论是脏页还是干净页，都在内存中。平时执行很快的更新操作，其实就是在写内存和日志，而MySQL偶尔变慢的时候，可能就是在刷脏页（flush）。以下几种场景可能导致这种情况：

- 第一种场景是，InnoDB的redo log写满了。这时候系统会停止所有更新操作，把checkpoint往前推进，redo log留出空间可以继续写。如下图：![image-20191202232328797](https://learningpics.oss-cn-shenzhen.aliyuncs.com/images/image-20191202232328797-3704252.png)

> checkpoint可不是随便往前修改一下位置就可以的。比如图中，**把checkpoint位置从CP推进到CP’，就需要将两个点之间的日志（浅绿色部分），对应的所有脏页都flush到磁盘上。**之后，图中从write pos到CP’之间就是可以再写入的redo log的区域。

- 第二种场景是，系统内存不足。==当需要新的内存页，而内存不够用的时候，就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是“脏页”，就要先将脏页写到磁盘。==
  之所以不直接把内存淘汰掉，然后下次需要请求的时候，从磁盘读入数据页，然后拿redo log出来应用的原因是：要从性能考虑的。如果刷脏页一定会写盘，就保证了每个数据页有两种状态：

  - 一种是内存里存在，内存里就肯定是正确的结果，直接返回；

  - 另一种是内存里没有数据，就可以肯定数据文件上是正确的结果，读入内存后返回。

    > 这样的效率最高。

- 第三种场景是，MySQL认为系统“空闲”的时候。当然，MySQL忙起来可能也会很快就能把redo log记满的，所以只要有机会就刷一点“脏页”。

- 第四种场景是，MySQL正常关闭的情况。这时候，MySQL会把内存的脏页都flush到磁盘上，这样下次MySQL启动的时候，就可以直接从磁盘上读数据，启动速度会很快。

下面看看**上面四种场景对性能的影响。**

其中，第三种情况是属于MySQL空闲时的操作，这时系统没什么压力，而第四种场景是数据库本来就要关闭了。这两种情况下，不会太关注“性能”问题。所以下面主要来分析一下前两种场景下的性能问题。

- 第一种是“redo log写满了，要flush脏页”，这种情况是InnoDB要尽量避免的。因为出现这种情况的时候，整个系统就不能再接受更新了，所有的更新都必须堵住。如果你从监控上看，这时候更新数会跌为0。
- 第二种是“内存不够用了，要先将脏页写到磁盘”，这种情况其实是常态。**InnoDB用缓冲池（buffer pool）管理内存，缓冲池中的内存页有三种状态：**
  - 第一种是，还没有使用的；
  - 第二种是，使用了并且是干净页；
  - 第三种是，使用了并且是脏页。

==InnoDB的策略是尽量使用内存，因此对于一个长时间运行的库来说，未被使用的页面很少。==而当要读入的数据页没有在内存的时候，就必须到缓冲池中申请一个数据页。这时候只能把最久不使用的数据页从内存中淘汰掉：如果要淘汰的是一个干净页，就直接释放出来复用；但如果是脏页呢，就必须将脏页先刷到磁盘，变成干净页后才能复用。

所以，刷脏页虽然是常态，但是出现以下这两种情况，都是会明显影响性能的：

1. 一个查询要淘汰的脏页个数太多，会导致查询的响应时间明显变长；
2. 日志写满，更新全部堵住，写性能跌为0，这种情况对敏感业务来说，是不能接受的。

所以，InnoDB需要有控制脏页比例的机制，来尽量避免上面的这两种情况。

## InnoDB刷脏页的控制策略

​	首先，你要正确地告诉InnoDB所在主机的IO能力，这样InnoDB才能知道需要全力刷脏页的时候，可以刷多快。**这就要用到`innodb_io_capacity`这个参数了，它会告诉InnoDB你的磁盘能力。**这个值建议设置成磁盘的IOPS。磁盘的IOPS可以通过fio这个工具来测试，下面的语句可以用来测试磁盘随机读写的命令：

```
 fio -filename=$filename -direct=1 -iodepth 1 -thread -rw=randrw -ioengine=psync -bs=16k -size=500M -numjobs=10 -runtime=10 -group_reporting -name=mytest 
```

其实，因为没能正确地设置innodb_io_capacity参数，而导致的性能问题也比比皆是。比如说MySQL的写入速度很慢，TPS很低，但是数据库主机的IO压力并不大。可能就是这个参数的设置出了问题。

> 主机磁盘用的是SSD，但是innodb_io_capacity的值设置的是300。于是，InnoDB认为这个系统的能力就这么差，所以刷脏页刷得特别慢，甚至比脏页生成的速度还慢，这样就造成了脏页累积，影响了查询和更新性能。

如果刷太慢，可能会出现内存脏页太多，或者redo log写满。所以，InnoDB的刷盘速度就是要参考这两个因素：一个是脏页比例，一个是redo log写盘速度。

**InnoDB会根据这两个因素先单独算出两个数字。**

==参数`innodb_max_dirty_pages_pct`是脏页比例上限，默认值是75%。InnoDB会根据当前的脏页比例（假设为M），算出一个范围在0到100之间的数字==，计算这个数字的伪代码类似这样：

```
F1(M)
{
  if M>=innodb_max_dirty_pages_pct then
      return 100;
  return 100*M/innodb_max_dirty_pages_pct;
}
```

InnoDB每次写入的日志都有一个序号，当前写入的序号跟checkpoint对应的序号之间的差值，假设为N。InnoDB会根据这个N算出一个范围在0到100之间的数字，这个计算公式可以记为F2(N)，N越大，算出来的值越大就好了。

> 每个数据页头部有LSN，8字节，每次修改都会变大。对比这个LSN跟checkpoint 的LSN，比checkpoint小的一定是干净页。LSN是每次写redo log都带的一个数字， 数据页上也有，对比大小的，

然后，**根据上述算得的F1(M)和F2(N)两个值，取其中较大的值记为R，之后引擎就可以按照innodb_io_capacity定义的能力乘以R%来控制刷脏页的速度。**如下图：

![img](https://learningpics.oss-cn-shenzhen.aliyuncs.com/images/cc44c1d080141aa50df6a91067475374.png)

​	==InnoDB会在后台刷脏页，而刷脏页的过程是要将内存页写入磁盘。==所以，无论查询语句在需要内存的时候可能要求淘汰一个脏页，还是由于刷脏页的逻辑会占用IO资源并可能影响到了你的更新语句，都可能是MySQL突然变慢的原因。

> 要尽量避免这种情况，就要合理地设置innodb_io_capacity的值，并且**平时要多关注脏页比例，不要让它经常接近75%**。

其中，脏页比例是通过`Innodb_buffer_pool_pages_dirty/Innodb_buffer_pool_pages_total`得到的，具体的命令参考下面的代码：

```
mysql> select VARIABLE_VALUE into @a from global_status where VARIABLE_NAME = 'Innodb_buffer_pool_pages_dirty';
select VARIABLE_VALUE into @b from global_status where VARIABLE_NAME = 'Innodb_buffer_pool_pages_total';
select @a/@b;
```

一旦一个查询请求需要在执行过程中先flush掉一个脏页时，这个查询就可能要比平时慢了。而MySQL中的一个机制，可能让你的查询会更慢：==在准备刷一个脏页的时候，如果这个数据页旁边的数据页刚好是脏页，就会把这个“邻居”也带着一起刷掉；而且这个把“邻居”拖下水的逻辑还可以继续蔓延，也就是对于每个邻居数据页，如果跟它相邻的数据页也还是脏页的话，也会被放到一起刷。==

在InnoDB中，`innodb_flush_neighbors `参数就是用来控制这个行为的，**值为1的时候会有上述的“连坐”机制，值为0时表示不找邻居，自己刷自己的。**

> 找“邻居”这个优化在机械硬盘时代是很有意义的，可以减少很多随机IO。机械硬盘的随机IOPS一般只有几百，相同的逻辑操作减少随机IO就意味着系统性能的大幅度提升。而如果使用的是SSD这类IOPS比较高的设备的话，建议把innodb_flush_neighbors的值设置成0。因为这时候IOPS往往不是瓶颈，而“只刷自己”，就能更快地执行完必要的刷脏页操作，减少SQL语句响应时间。
>
> ==在MySQL 8.0中，innodb_flush_neighbors参数的默认值已经是0了。==

## 小结

​	利用WAL技术，数据库将随机写转换成了顺序写，大大提升了数据库的性能。但是，由此也带来了内存脏页的问题。**脏页会被后台线程自动flush，也会由于数据页淘汰而触发flush，而刷脏页的过程由于会占用资源，可能会让你的更新和查询语句的响应时间长一些。**

# 十一、数据库表的空间回收

​	**一个InnoDB表包含两部分，即：表结构定义和数据。**在MySQL 8.0版本以前，表结构是存在以.frm为后缀的文件里。而MySQL 8.0版本，则已经允许把表结构定义放在系统数据表中了。因为表结构定义占用的空间很小，所以下面主要讨论的是表数据。

## 参数innodb_file_per_table

**表数据既可以存在共享表空间里，也可以是单独的文件。**这个行为是由参数`innodb_file_per_table`控制的：

1. 这个参数设置为OFF表示的是，表的数据放在系统共享表空间，也就是跟数据字典放在一起；
2. 这个参数设置为ON表示的是，每个InnoDB表数据存储在一个以 .ibd为后缀的文件中。

从MySQL 5.6.6版本开始，它的默认值就是ON了。

> 我建议不论使用MySQL的哪个版本，都将这个值设置为ON。因为，一个表单独存储为一个文件更容易管理，而且在你不需要这个表的时候，**通过`drop table`命令，系统就会直接删除这个文件。**而如果是放在共享表空间中，即使表删掉了，空间也是不会回收的。

​	在删除整个表的时候，可以使用`drop table`命令回收表空间。但是，我们遇到的更多的删除数据的场景是删除某些行，可能会出现：表中的数据被删除了，但是表空间却没有被回收。下面主要讨论这个问题。

## 数据删除流程

​	下面先再来看一下InnoDB中一个索引的示意图，InnoDB里的数据都是用B+树的结构组织的。

![image-20191203232004194](https://learningpics.oss-cn-shenzhen.aliyuncs.com/images/image-20191203232004194.png)

​	假设，**要删掉R4这个记录，InnoDB引擎只会把R4这个记录标记为删除。如果之后要再插入一个ID在300和600之间的记录时，可能会复用这个位置。但是，磁盘文件的大小并不会缩小。**

​	InnoDB的数据是按页存储的，那么如果我们删掉了一个数据页上的所有记录，则整个数据页就可以被复用了。但是，**数据页的复用跟记录的复用是不同的。**

- 记录的复用，只限于符合范围条件的数据。比如上面的这个例子，R4这条记录被删除后，如果插入一个ID是400的行，可以直接复用这个空间。但如果插入的是一个ID是800的行，就不能复用这个位置了。
- 而当整个页从B+树里面摘掉以后，可以复用到任何位置。以上图为例，**如果将数据页page A上的所有记录删除以后，page A会被标记为可复用。这时候如果要插入一条ID=50的记录需要使用新页的时候，page A是可以被复用的。**

> 如果相邻的两个数据页利用率都很小，系统就会把这两个页上的数据合到其中一个页上，另外一个数据页就被标记为可复用。

​	==所以如果用delete命令把整个表的数据删除就会导致所有的数据页都会被标记为可复用。但是磁盘上，文件不会变小。==**delete命令其实只是把记录的位置，或者数据页标记为了“可复用”，但磁盘文件的大小是不会变的。也就是说，通过delete命令是不能回收表空间的。这些可以复用，而没有被使用的空间，看起来就像是“空洞”。**

==实际上，**不止是删除数据会造成空洞，插入数据也会。**==

如果数据是按照索引递增顺序插入的，那么索引是紧凑的。但如果数据是随机插入的，就可能造成索引的数据页分裂。

假设上图中page A已经满了，这时再插入一行数据，就会出现下图的情况：

![img](https://learningpics.oss-cn-shenzhen.aliyuncs.com/images/8083f05a4a4c0372833a6e01d5a8e6ea.png)

可以看到，由于page A满了，再插入一个ID是550的数据时，就不得不再申请一个新的页面page B来保存数据了。页分裂完成后，**page A的末尾就留下了空洞**（注意：实际上，可能不止1个记录的位置是空洞）。

另外，更新索引上的值，可以理解为删除一个旧的值，再插入一个新值。不难理解，这也是会造成空洞的。也就是说，经过大量增删改的表，都是可能是存在空洞的。所以，如果能够把这些空洞去掉，就能达到收缩表空间的目的。==而重建表，就可以达到这样的目的。==

## 重建表

​	**可以通过新建一个与表A结构相同的表B，然后按照主键ID递增的顺序，把数据一行一行地从表A里读出来再插入到表B中，这样就可以实现对表A的空间收缩。**

​	由于表B是新建的表，所以表A主键索引上的空洞，在表B中就都不存在了。显然地，表B的主键索引更紧凑，数据页的利用率也更高。如果我们把表B作为临时表，数据从表A导入表B的操作完成后，用表B替换A，从效果上看，就起到了收缩表A空间的作用。

​	可以使用`alter table A engine=InnoDB`命令来重建表。在MySQL 5.5版本之前，这个命令的执行流程上面描述的差不多，区别只是这个临时表B不需要你自己创建，MySQL会自动完成转存数据、交换表名、删除旧表的操作。

![image-20191203232557769](https://learningpics.oss-cn-shenzhen.aliyuncs.com/images/image-20191203232557769.png)

显然，花时间最多的步骤是往临时表插入数据的过程，如果在这个过程中，有新的数据要写入到表A的话，就会造成数据丢失。因此，在整个DDL过程中，表A中不能有更新。也就是说，这个DDL不是Online的。

而在**MySQL 5.6版本开始引入的Online DDL，对这个操作流程做了优化。**

引入了Online DDL之后，重建表的流程：

1. 建立一个临时文件，扫描表A主键的所有数据页；
2. 用数据页中表A的记录生成B+树，存储到临时文件中；
3. 生成临时文件的过程中，将所有对A的操作记录在一个==日志文件（row log）==中，对应的是图中state2的状态；
4. 临时文件生成后，将日志文件中的操作应用到临时文件，得到一个逻辑数据上与表A相同的数据文件，对应的就是图中state3的状态；
5. 用临时文件替换表A的数据文件。

![image-20191203232656318](https://learningpics.oss-cn-shenzhen.aliyuncs.com/images/image-20191203232656318.png)

​	可以看到，与上一张图过程的不同之处在于，由于日志文件记录和重放操作这个功能的存在，这个方案在**重建表的过程中，允许对表A做增删改操作**。这也就是Online DDL名字的来源。

​	DDL之前是要拿MDL写锁的，在图中的流程中，**alter语句在启动的时候需要获取MDL写锁，但是这个写锁在真正拷贝数据之前就退化成读锁了。**为了实现Online，MDL读锁不会阻塞增删改操作。不直接解锁是为了保护自己，禁止其他线程对这个表同时做DDL。

​	而对于一个大表来说，Online DDL最耗时的过程就是拷贝数据到临时表的过程，这个步骤的执行期间可以接受增删改操作。所以，相对于整个DDL过程来说，锁的时间非常短。对业务来说，就可以认为是Online的。

> 需要补充说明的是，上述的这些重建方法都会扫描原表数据和构建临时文件。对于很大的表来说，这个操作是很消耗IO和CPU资源的。因此，如果是线上服务，要很小心地控制操作时间。如果想要比较安全的操作的话，可以使用GitHub开源的gh-ost来做。

## Online 和 inplace

​	在上面的图中，**把表A中的数据导出来的存放位置叫作tmp_table。这是一个临时表，是在server层创建的。**

根据表A重建出来的数据是放在“tmp_file”里的，这个临时文件是InnoDB在内部创建出来的。**整个DDL过程都在InnoDB内部完成。对于server层来说，没有把数据挪动到临时表，是一个“原地”操作，这就是“inplace”名称的来源。**

> 如果你有一个1TB的表，现在磁盘间是1.2TB，是不能做一个inplace的DDL。因为，==tmp_file也是要占用临时空间的。==

重建表的这个语句alter table t engine=InnoDB，其实隐含的意思是：

`alter table t engine=innodb,ALGORITHM=inplace;`

跟inplace对应的就是拷贝表的方式了，用法是：

`alter table t engine=innodb,ALGORITHM=copy;`

当你使用ALGORITHM=copy的时候，表示的是强制拷贝表，对应的流程就是上面倒数第二个图的操作过程。

> inplace跟Online只是在重建表这个逻辑中刚好是这样而已。

比如，如果要给InnoDB表的一个字段加全文索引，写法是：

`alter table t add FULLTEXT(field_name);`

这个过程是inplace的，但会阻塞增删改操作，是非Online的。如果说这两个逻辑之间的关系是什么的话，可以概括为：

1. DDL过程如果是Online的，就一定是inplace的；
2. 反过来未必，也就是说inplace的DDL，有可能不是Online的。**截止到MySQL 8.0，添加全文索引（FULLTEXT index）和空间索引(SPATIAL index)就属于这种情况。**

> optimize table、analyze table和alter table这三种方式重建表的区别：
>
> - 从MySQL 5.6版本开始，alter table t engine = InnoDB（也就是recreate）默认的就是上面最后一张图的流程了；
> - analyze table t 其实不是重建表，只是对表的索引信息做重新统计，没有修改数据，这个过程中加了MDL读锁；
> - optimize table t 等于recreate+analyze。
>
> Truncate 可以理解为drop+create

> 什么时候使用alter table t engine=InnoDB会让一个表占用的空间反而变大。
>
> 这个表，本身就已经没有空洞的了，比如说刚刚做过一次重建表操作。在DDL期间，如果刚好有外部的DML在执行，这期间可能会引入一些新的空洞。
>
> 或者
>
> 在重建表的时候，InnoDB不会把整张表占满，每个页留了1/16给后续的更新用。也就是说，其实重建表之后不是“最”紧凑的。
>
> 假如是这么一个过程：
>
> 1. 将表t重建一次；
> 2. **插入一部分数据，但是插入的这些数据，用掉了一部分的预留空间；**
> 3. 这种情况下，再重建一次表t，就可能会出现问题中的现象。

# 十二、count(*)

## count(*)的实现方式

在不同的MySQL引擎中，count(*)有不同的实现方式。

- MyISAM引擎把一个表的总行数存在了磁盘上，因此执行count(*)的时候会直接返回这个数，效率很高；
- 而InnoDB引擎就麻烦了，它执行count(*)的时候，需要把数据一行一行地从引擎里面读出来，然后累积计数。

> 这里说的都是没有过滤条件的count(*)，如果加了where 条件的话，MyISAM表也是不能返回得这么快的。

InnoDB之所以不跟MyISAM一样，也把数字存起来，是因为即使是在同一个时刻的多个查询，由于多版本并发控制（MVCC）的原因，InnoDB表“应该返回多少行”也是不确定的。下面来看一个算count(*)的例子。

这是因为即使是在同一个时刻的多个查询，由于多版本并发控制（MVCC）的原因，InnoDB表“应该返回多少行”也是不确定的。这里，我用一个算count(*)的例子来为你解释一下。

假设表t中现在有10000条记录，设计了三个用户并行的会话。

- 会话A先启动事务并查询一次表的总行数；
- 会话B启动事务，插入一行后记录后，查询表的总行数；
- 会话C先启动一个单独的语句，插入一行记录后，查询表的总行数。

我们假设从上到下是按照时间顺序执行的，同一行语句是在同一时刻执行的。

![img](https://learningpics.oss-cn-shenzhen.aliyuncs.com/images/5e716ba1d464c8224c1c1f36135d0e97.png)

如图，在最后一个时刻，三个会话A、B、C会同时查询表t的总行数，但拿到的结果却不同。

这和InnoDB的事务设计有关系，可重复读是它默认的隔离级别，在代码上就是通过多版本并发控制，也就是MVCC来实现的。**每一行记录都要判断自己是否对这个会话可见，因此对于count(*)请求来说，InnoDB只好把数据一行一行地读出依次判断，可见的行才能够用于计算“基于这个查询”的表的总行数。**

​	==InnoDB是索引组织表，主键索引树的叶子节点是数据，而普通索引树的叶子节点是主键值。所以，普通索引树比主键索引树小很多==。对于count(*)这样的操作，遍历哪个索引树得到的结果逻辑上都是一样的。因此，MySQL优化器会找到最小的那棵树来遍历。**在保证逻辑正确的前提下，尽量减少扫描的数据量，是数据库系统设计的通用法则之一。**

​	此外，`show table status` 这个命令的输出结果里面也有一个TABLE_ROWS用于显示这个表当前有多少行，这个命令执行挺快的，但是TABLE_ROWS不能代替count(*)。实际上，TABLE_ROWS就是从采样估算（索引统计的值）得来的，因此它也很不准。有多不准呢，官方文档说误差可能达到40%到50%。所以，show table status命令显示的行数也不能直接使用。

实际上，TABLE_ROWS就是从这个采样估算得来的，因此它也很不准。有多不准呢，官方文档说误差可能达到40%到50%。**所以，show table status命令显示的行数也不能直接使用。**

下面做个对比：

- MyISAM表虽然count(*)很快，但是不支持事务；
- show table status命令虽然返回很快，但是不准确；
- InnoDB表直接count(*)会遍历全表，虽然结果准确，但会导致性能问题。

假如有一个页面经常要显示交易系统的操作记录总数，我们就要自己实现计数方法了，其实就是找一个地方，把操作记录表的行数存起来。下面来看看一些计数方案。

## 用缓存系统保存计数

​	可以用一个Redis服务来保存这个表的总行数。这个表每被插入一行Redis计数就加1，每被删除一行Redis计数就减1。这种方式下，读和更新操作都很快，**但是缓存系统可能会丢失更新。**

​	Redis的数据不能永久地留在内存里，所以需要找一个地方把这个值定期地持久化存储起来。但即使这样，仍然可能丢失更新。试想如果刚刚在数据表中插入了一行，Redis中保存的值也加了1，然后Redis异常重启了，重启后你要从存储redis数据的地方把这个值读回来，而刚刚加1的这个计数操作却丢失了。

​	不过这还是有解的。比如，Redis异常重启以后，到数据库里面单独执行一次count(*)获取真实的行数，再把这个值写回到Redis里就可以了。异常重启毕竟不是经常出现的情况，这一次全表扫描的成本，还是可以接受的。

但实际上，**将计数保存在缓存系统中的方式，还不只是丢失更新的问题。即使Redis正常工作，这个值还是逻辑上不精确的。**

比如说，要显示操作记录的总数，同时还要显示最近操作的100条记录。那么，这个页面的逻辑就需要先到Redis里面取出计数，再到数据表里面取数据记录。

有两种不大精确的情况：

1. 一种是，查到的100行结果里面有最新插入记录，而Redis的计数里还没加1；
2. 另一种是，查到的100行结果里没有最新插入的记录，而Redis的计数里已经加了1。

这两种情况，都是逻辑不一致的。下面一起来看看这个时序图。

![img](https://learningpics.oss-cn-shenzhen.aliyuncs.com/images/39898af053695dad37227d71ae288e33.png)

上图中，会话A是一个插入交易记录的逻辑，往数据表里插入一行R，然后Redis计数加1；会话B就是查询页面显示时需要的数据。

在上图的这个时序里，在T3时刻会话B来查询的时候，会显示出新插入的R这个记录，但是Redis的计数还没加1。这时候，就会出现我们说的数据不一致。

你一定会说，这是因为我们执行新增记录逻辑时候，是先写数据表，再改Redis计数。而读的时候是先读Redis，再读数据表，这个顺序是相反的。那么，如果保持顺序一样的话，是不是就没问题了？我们现在把会话A的更新顺序换一下，再看看执行结果。

![img](https://learningpics.oss-cn-shenzhen.aliyuncs.com/images/5c2f786beae1d8917cdc5033b7bf0bdb.png)

你会发现，这时候反过来了，会话B在T3时刻查询的时候，Redis计数加了1了，但还查不到新插入的R这一行，也是数据不一致的情况。

**在并发系统里面，我们是无法精确控制不同线程的执行时刻的，因为存在图中的这种操作序列，所以，我们说即使Redis正常工作，这个计数值还是逻辑上不精确的。**

## 在数据库保存计数

​	根据上面的分析，用缓存系统保存计数有丢失数据和计数不精确的问题。那么，**如果我们把这个计数直接放到数据库里单独的一张计数表C中，又会怎么样呢？**

首先，这解决了崩溃丢失的问题，InnoDB是支持崩溃恢复不丢数据的。然后，我们再看看能不能解决计数不精确的问题。

count(\*)有时候变慢主要是由于InnoDB要支持事务，从而导致InnoDB表不能把count(*)直接存起来，然后查询的时候直接返回形成的。

所谓以子之矛攻子之盾，现在我们就利用“事务”这个特性，把问题解决掉。

![img](https://learningpics.oss-cn-shenzhen.aliyuncs.com/images/9e4170e2dfca3524eb5e92adb8647de3.png)

我们来看下现在的执行结果。虽然会话B的读操作仍然是在T3执行的，但是因为这时候更新事务还没有提交，所以计数值加1这个操作对会话B还不可见。

因此，会话B看到的结果里， 查计数值和“最近100条记录”看到的结果，逻辑上就是一致的。

> ==把计数放在Redis里面，不能够保证计数和MySQL表里的数据精确一致的原因，是**这两个不同的存储构成的系统，不支持分布式事务，无法拿到精确一致的视图。**而把计数值也放在MySQL中，就解决了一致性视图的问题。==

## 不同的count用法

​	下面开看看count(*)、count(主键id)、count(字段)和count(1)这几种不同用法的性能有哪些差别，需要注意的是，下面的讨论还是基于InnoDB引擎的。

​	首先，要先了解count()的语义。**count()是一个聚合函数，对于返回的结果集，一行行地判断，如果count函数的参数不是NULL，累计值就加1，否则不加。最后返回累计值。**

所以，==count(*)、count(主键id)和count(1) 都表示返回满足条件的结果集的总行数；而count(字段），则表示返回满足条件的数据行里面，参数“字段”不为NULL的总个数。==

至于分析性能差别的时候，可以记住这么几个原则：

1. server层要什么就给什么；
2. InnoDB只给必要的值；
3. 现在的优化器只优化了count(*)的语义为“取行数”，其他“显而易见”的优化并没有做。

接下来，我们就一个个地来看看。

**对于count(主键id)来说**，InnoDB引擎会遍历整张表，**把每一行的id值都取出来，返回给server层。server层拿到id后，判断是不可能为空的，就按行累加。**

**对于count(1)来说**，InnoDB引擎遍历整张表，但不取值。server层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加。

> 单看这两个用法的差别的话，你能对比出来，count(1)执行得要比count(主键id)快。因为从引擎返回id会涉及到解析数据行，以及拷贝字段值的操作。

**对于count(字段)来说**：

1. 如果这个“字段”是定义为not null的话，一行行地从记录里面读出这个字段，判断不能为null，按行累加；
2. 如果这个“字段”定义允许为null，那么执行的时候，判断到有可能是null，还要把值取出来再判断一下，不是null才累加。

也就是前面的第一条原则，server层要什么字段，InnoDB就返回什么字段。

**但是count(\*)是例外**，并不会把全部字段取出来，而是专门做了优化，不取值。count(\*)肯定不是null，按行累加。MySQL专门针对这个语句进行优化，也不是不可以。但是这种需要专门优化的情况太多了，而且MySQL已经优化过count(*)了，你直接使用这种用法就可以了。

所以结论是：==按照效率排序的话，count(字段)<count(主键id)<count(1)≈count(\*)，所以建议尽量使用count(*)。==

> 在刚刚讨论的方案中，我们用了事务来确保计数准确。由于事务可以保证中间结果不被别的事务读到，因此修改计数值和插入新记录的顺序是不影响逻辑结果的。但是，从并发系统性能的角度考虑，你觉得在这个事务序列里，应该先插入操作记录，还是应该先更新计数表呢？
>
> 应该先插入操作记录，再更新计数表。==因为更新计数表涉及到行锁的竞争，先插入再更新能最大程度地减少了事务之间的锁等待，提升了并发度。==





